{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Lab 07 : More Problem Solving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "The main objectives of this lab are as follows.\n",
    "\n",
    "- Numerically calculate the Jacobian matrix.\n",
    "- Use broadcasting to do a calculation without loops!\n",
    "- Prepare for the lab!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always you should add initialization to the top of your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1b56cb89f7a91c91e1f6bb1f905cc6d2",
     "grade": true,
     "grade_id": "cell-365cf35978c971ea",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.optimize as opt\n",
    "import scipy.interpolate as interp\n",
    "import scipy.special as sf\n",
    "import matplotlib as mpl\n",
    "mpl.rc('xtick', direction='in', top=True)\n",
    "mpl.rc('ytick', direction='in', right=True)\n",
    "mpl.rc('xtick.minor', visible=True)\n",
    "mpl.rc('ytick.minor', visible=True)\n",
    "import scipy.integrate as integ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacobian Matrix\n",
    "\n",
    "For a system of functions of many variables, $\\vec f(\\vec x)$, we have seen that the Jacobian matrix, $\\mathsf{J}_{\\vec f}(\\vec x)$ can be written as\n",
    "$$\n",
    "\\mathsf{J}_{\\vec f} (\\vec x) = \\begin{pmatrix}\n",
    "\\frac{\\partial f_1}{\\partial x_1} & \\frac{\\partial f_1}{\\partial x_2} & \\cdots \\\\\n",
    "\\frac{\\partial f_2}{\\partial x_1} & \\frac{\\partial f_2}{\\partial x_2} & \\cdots \\\\\n",
    "\\vdots & \\vdots & \\ddots\n",
    "\\end{pmatrix},\n",
    "$$\n",
    "or in other words that the components are just\n",
    "$$ J_{ij}(\\vec x) = \\frac{\\partial f_i(\\vec x)}{\\partial x_j}. $$\n",
    "\n",
    "Here we will construct this matrix both analytically and numerically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple System\n",
    "\n",
    "As a simple example let us consider two functions:\n",
    "\\begin{align}\n",
    "f_1(\\vec x) & = x_1 \\sin(x_2) \\\\\n",
    "f_2(\\vec x) & = 2 x_2 \\cos(x_1)\n",
    "\\end{align}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analytically calculate the Jacobian matrix and write it using LaTeX below. (*Hint:* See above for how to a simply way to typeset a matrix in LaTeX.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "64b767cb96501daa215829f3e2446bc1",
     "grade": true,
     "grade_id": "cell-8a7b85882f57ea7e",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "$$\n",
    "\\mathsf{J}_{\\vec f} (\\vec x) = \\begin{pmatrix}\n",
    "\\sin(x_2) & x_1\\cos(x_2) \\\\\n",
    "-2x_2\\sin(x_1) & 2\\cos(x_1)\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python function that calculates the Jacobian matrix and returns it as a two dimensional NumPy array.  Your function must be of the form\n",
    "```\n",
    "def Jacobian_analytic (x) :\n",
    "```\n",
    "where `x` will be a two component array.  It must return a $2\\times2$ `numpy` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ab7086313ac3162626294dba388286a8",
     "grade": false,
     "grade_id": "cell-9eff3b271fde5ce1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def Jacobian_analytic (x) :\n",
    "    \"\"\"Calculates the Jacobian matrix and returns\n",
    "    it as a two dimensional NumPy array.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : a two component array containing;\n",
    "        x[0] : x1\n",
    "        x[0] : x2\n",
    "        \"\"\"\n",
    "    jac = np.zeros((2,2))\n",
    "    jac[0][0] = np.sin(x[1])\n",
    "    jac[0][1] = x[0]*np.cos(x[1])\n",
    "    jac[1][0] = -2*x[1]*np.sin(x[0])\n",
    "    jac[1][1] = 2*np.cos(x[0])\n",
    "    return jac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simple choices of $x_1$ and $x_2$, write a test case for your function `Jacobian_analytic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct simple choices of x1 and x2\n",
    "x1 = np.pi/4\n",
    "x2 = np.pi/6\n",
    "x = np.array([x1, x2])\n",
    "\n",
    "#Construct Jacobian matrix for these valuse of x1 and x2\n",
    "J = np.array([[.5, np.sqrt(3)*np.pi/8],\n",
    "              [-np.pi/6*np.sqrt(2), np.sqrt(2)]])\n",
    "\n",
    "#Test Jacobian_analytic\n",
    "Ja = Jacobian_analytic(x)\n",
    "assert(np.allclose(J,Ja))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4eb2ba861aff87e440a95a40ec6f9b31",
     "grade": true,
     "grade_id": "cell-a49a079f1dfd345e",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Jacobian Matrix\n",
    "\n",
    "We can also calculate the Jacobian matrix by calculating the derivatives of the functions numerically.  Here we will use center differencing to calculate the derivatives (in many libraries forward differencing is used for this purpose)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, write a function that evaluates our system of functions.  This function must work on a two dimensional array of input values of shape $(2, N)$, similar to what we did for last weeks lab.  Verify that if you pass in a $(2, N)$ array, it returns a $(2,N)$ array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cc9460ba9ae192eef7714ad21565686f",
     "grade": true,
     "grade_id": "cell-ed7b8a53c4dd9e09",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def funcs (x) :\n",
    "    \"\"\"Evaluates our system of functions. Returns the function\n",
    "    values.\n",
    "    Parameter\n",
    "    x : A (2, N) array of values to evaluate the system of functions at.\n",
    "        x[0] : x1 values\n",
    "        x[1] : x2 values\n",
    "    \"\"\"\n",
    "    f = np.zeros_like(x)\n",
    "    f[0] = x[0]*np.sin(x[1])\n",
    "    f[1] = 2*x[1]*np.cos(x[0])\n",
    "    return f\n",
    "\n",
    "#Make sure returned array is the correct shape\n",
    "x_test = np.random.rand(2, 12)\n",
    "f_test = funcs(x_test)\n",
    "assert(x_test.shape == f_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know how to calculate the derivative using center differencing for a single function of one variable.  How do we do it for many functions of many variables?  Here we can use **broadcasting** to help us.  In our case we will use a step size $h_1=1\\times 10^{-5}$ to calculate derivatives with respect to $x_1$ and $h_2=5\\times 10^{-6}$ to calculate derivatives with respect to $x_2$.\n",
    "\n",
    "For the case we are considering here, in the Jacobian matrix we need to calculate four different derivatives.  In each derivative we only want to change one of the $x_i$ using the associated $h_i$.  How can we do this without a loop?\n",
    "\n",
    "To see how to do this, let us begin by calculating the first column of the Jacobian matrix.  Here we are taking derivatives of both of our functions with respect to $x_1$ only.  We know how to do that using center differencing.  In this case we can let\n",
    "```\n",
    "h = np.array([1e-5, 0])\n",
    "```\n",
    "then `x+h` and `x-h` will *do the right thing* and only change $x_1$, not $x_2$. (Recall that we should not use $h$ as we have written it.  Numerically we want to have an \"exact\" $h$.  We have seen how to do this a number of times.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerically calculate the first column of the Jacobian matrix using center differencing.  Use `assert` to verify that your results are in good agreement with the first column of your analytic Jacobian. For this test use $x_1=\\pi/8$ and $x_2=\\pi/4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "743882e9e6787fd12058af2dda2d35b5",
     "grade": true,
     "grade_id": "cell-4c923756a3552867",
     "locked": false,
     "points": 0.75,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#Construct constants and array\n",
    "x1 = np.pi/8\n",
    "x2 = np.pi/4\n",
    "x = np.array([x1, x2])\n",
    "\n",
    "h10 = 1e-05\n",
    "h1 = np.array([x1+h10, 0])\n",
    "h1 -= np.array([x1, 0])\n",
    "\n",
    "h20 = 5e-06\n",
    "h2 = np.array([0, x2+h20])\n",
    "h2 -= np.array([0, x2])\n",
    "\n",
    "#Caclulate Jacobian numerically\n",
    "Jn = np.zeros((2,2))\n",
    "Jn[:,0] = (funcs(x+h1)-funcs(x-h1))/(2*np.linalg.norm(h1))\n",
    "Jn[:,1] = (funcs(x+h2)-funcs(x-h2))/(2*np.linalg.norm(h2))\n",
    "\n",
    "#Test numerical calculation\n",
    "Ja = Jacobian_analytic(x)\n",
    "assert(np.allclose(Ja,Jn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will calculate the full Jacobian matrix using broadcasting.  Here is how we can do it.  Let `h` be an array containing $h_1$ and $h_2$.  Next we can construct a diagonal matrix with each value of `h` on the diagonal using `np.diag(h)`.  Then we can add (or subtract) this from `x` to get one of $x_1$ or $x_2$ shifted by the appropriate $h_i$ in a $2\\times2$ array.  Finally, we can feed this to `funcs` to evaluate our system of functions as the appropriate points and use this to calculate the derivatives using center differencing and ultimately construct the Jacobian.\n",
    "\n",
    "All of that sounds confusing.  Here is where using an interactive, interpreted language is great: we can test and explore each step.  Begin by constructing the `h` array.  Then turn it into a two dimensional array.  Add (or subtract) it from `x`, what does that look like?  Pass this result to `funcs`, what does it look like?  Are they in the right order for the Jacobian?  Finally calculate the numerical derivatives.  We can compare them to our analytic Jacobian.  Of course everything is not going to work smoothly.  Some things will not be in the right place.  That is fine, we know how to swap rows and columns using the transpose!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerically calculate the Jacobian using center differencing.  Let use call it `J`.  We will next want to compare it to `Jacobian_analytic` so you should make sure your `J` is ordered the same way as you get from `Jacobian_analytic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "93d2c589a5625df07a77d1af4211d848",
     "grade": false,
     "grade_id": "cell-59e11ffc8777c718",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#Make array for h\n",
    "h = np.array([h1, h2])\n",
    "\n",
    "#Caclulate Jacobian numerically with broadcastin\n",
    "J = (funcs(np.transpose(x+h))-funcs(np.transpose(x-h)))/(2*np.array([h1[0], h2[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a test using `assert` to verify that your `J` agrees with `Jacobian_analytic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(np.allclose(J, Ja))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "313451fbf8ffb89ded5f5243d3aabb87",
     "grade": true,
     "grade_id": "cell-e804d293c042642d",
     "locked": true,
     "points": 0.75,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are finally going to want to write a function to do the work for us.  As we have stated a few times, the computer cannot accurately represent all numbers so we should make sure that `h` is numerically \"exact\".  Though it is best to do this ourselves, here we will include this in our function.  This loses some efficiency and hides details that we really should not hide, but we will do it here anyway.\n",
    "\n",
    "Define a function to numerically calculate the Jacobian matrix using center differencing.  This function takes as input a function `f` which evaluates the system of functions, an array `x` which is the point at which we are evaluating the Jacobian, and an array `h10` which are the step sizes to use for calculating the derivatives.  Do not forget to document your function!\n",
    "\n",
    "(Notice that we do not include a method for passing in extra arguments to our function, `f`.  We know how we could do this.  Alternatively, since it is not provided, we know how work around this when using `Jacobian` if `f` did require extra arguments!  We will include extra arguments in the lab.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9e14b280603a679abdea4f7fbc5cb29a",
     "grade": false,
     "grade_id": "cell-ee0fba58f4ed661a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def Jacobian (f, x, h10) :\n",
    "    \"\"\"Caclulated the Jacobian of a function. Returns a 2D array\n",
    "    that represetn the Jacobian. The array is organized exactly like\n",
    "    the Jacobian is.\n",
    "    Parameters\n",
    "    ----------\n",
    "    f : the function to take the Jacobian of\n",
    "    x : the point to evaluate the Jacobian\n",
    "    h10 : an array of step sizes for calculating derivatives\n",
    "    \"\"\"\n",
    "    h = h10 + x\n",
    "    h -= x\n",
    "    d = np.diag(h)\n",
    "    J = (f(np.transpose(x+d))-f(np.transpose(x-d)))/(2*h)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, test your Jacobian function using `assert` by verifying that the numerical function produces the same result as the analytic function for some choice of `x` and `h10`. (Using the example from above is fine, though you can and should do multiple tests.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute Jacobian analytically\n",
    "Ja = Jacobian_analytic(x)\n",
    "\n",
    "#Compute Jacobian numerically\n",
    "h10 = np.array([h1[0], h2[1]])\n",
    "Jn = Jacobian(funcs, x, h10)\n",
    "\n",
    "#Test the numerical Jacobian\n",
    "assert(np.allclose(Jn, Ja))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a9c6e828618c5ee4af0ded6c054689fe",
     "grade": true,
     "grade_id": "cell-3c7174587affcb74",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Preparation\n",
    "\n",
    "The lab this week will involve the actual solution to that static spring-mass system.  Along the way we will encounter some issues so there are a number of steps that will be needed.  There are a few things that can/should be done to prepare for meeting with your group.  Some of them are listed here as things you should work on or check.  You do not need to include anything in the prelab, but any work you do now will make completing the lab easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definition and Tests\n",
    "\n",
    "In the previous lab you wrote a function defining the static conditions.  You also created some test cases.  It is essential that this function works!  To help make sure it does, here are a few test cases to compare against.  In all of these cases it must be true that $\\vec f(\\vec y)=0$.  If this is not true, then there is an error in your function and it must be corrected before you can proceed with the lab.\n",
    "\n",
    "First we consider two physically motivated test cases (these are taken from the Lab 06 solutions which will be posted after the next lab is completed).  These are not the only physical test cases that could have been created, they are just examples.  Note that in both of these cases there is freedom to make some choices, you can choose particular values or randomly assign them.  It would be good to run your visualization code also to make sure it produces the expected results.\n",
    "\n",
    "#### Physical test case 1\n",
    "\n",
    "A simple test case is when $k_1=k_2$, spring 3 is horizontal, and the masses are hanging straight down.  This means that $\\theta_1=\\theta_2=\\pi/2$ and $\\theta_3=0$.  We further need $\\ell_{0,3}=1$ and $\\ell_{0,1}=\\ell_{0,2}$.  Finally, we set $\\mu_1=\\mu_2$.  To achieve this case we need the force provided by springs 1 and 2 to balance gravity.  Thus we require $\\kappa_1 (\\ell_1 - \\ell_{0,1}) = \\mu_1$.  We can solve this equation for one of $\\kappa_1$, $\\ell_1$, $\\ell_{0,1}$, or $\\mu_1$ once we have specified the other quantities.\n",
    "\n",
    "#### Physical test case 2\n",
    "\n",
    "Another fairly simple case is when spring 2 (or equivalently spring 1) is missing.  In other words when $\\kappa_2=0$.  In this case the two masses just hang straight down and we need to satisfy the relations\n",
    "$$\n",
    "\\begin{align}\n",
    " \\kappa_1 \\Delta\\ell_1 &= \\mu_1 + \\mu_2 \\\\\n",
    " \\kappa_3 \\Delta\\ell_3 &= \\mu_2\n",
    "\\end{align}.\n",
    "$$\n",
    "If we arbitrarily choose $\\kappa_1$, $\\kappa_3$, $\\mu_1$, $\\mu_2$, and $\\ell_{0,i}$ we can then solve the above two equations for $\\ell_1$ and $\\ell_3$.  From these we then calculate\n",
    "$$\n",
    "\\ell_2 = \\sqrt{1+(\\ell_1+\\ell_3)^2} \\quad\\mathrm{and}\\quad \\tan\\theta_2 = \\frac{\\ell_1+\\ell_3}{1}.\n",
    "$$\n",
    "Finally, with $\\theta_1 = \\pi/2$ and $\\theta_3 = -\\pi/2$ (recall from the figure how we have defined $\\theta_3$) we have a valid static configuration.\n",
    "\n",
    "#### Symmetric case\n",
    "\n",
    "As a more complicated case you can consider a less trivial symmetric configuration.  Let $\\mu_1=\\mu_2 = 1/\\sqrt{3}$, $\\kappa_1=\\kappa_2=3$, $\\kappa_3=4$, $\\ell_{0,1}=\\ell_{0,2}=4/9$, and $\\ell_{0,3}=1/4$.  This produces a static configuration with $\\ell_1=\\ell_2 = 2/3$, $\\ell_3 = 1/3$, $\\theta_1=\\theta_2 = \\pi/3$, and $\\theta_3=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Work for the Lab\n",
    "\n",
    "When you read the lab you will see that there are a few functions we need to write.  A number of these can be done prior to working on the lab as a group.  In particular, converting the solutions to standard form in the function `to_standard_form()`, can be written independent of the lab.  Further, generalizing the Jacobian you wrote for the prelab to one that uses a function that takes extra arguments can be done.  Finally, even implementing the Newton-Raphson method can be done without direct reference to the problem we are solving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning in the PreLab\n",
    "\n",
    "All prelabs will be handled as was done for PreLab01.  See that file for details.  It will be assumed from now on that you have read and understood the procedure and what it means when you submit a prelab."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "authors": [
   {
    "name": "Craig J Copi",
    "semester": "Spring 2019"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
